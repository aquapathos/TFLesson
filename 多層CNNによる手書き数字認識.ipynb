{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多層CNNによるMNISTの手書き数字認識\n",
    "http://tensorflow.classcat.com/2016/03/10/tensorflow-cc-deep-mnist-for-experts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "import mytfext\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "※ tensorflow にはMNISTのサンプルデータをダウンロードするためのモジュールが備わっている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 重みの初期化関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def weight_variable(shape, name=\"\"):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    if name == \"\": \n",
    "        return tf.Variable(initial)\n",
    "    else:\n",
    "        return tf.Variable(initial,name=name)\n",
    "\n",
    "def bias_variable(shape, name=\"\"):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    if name == \"\": \n",
    "        return tf.Variable(initial)\n",
    "    else:\n",
    "        return tf.Variable(initial, name=mane)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 畳み込みとプーリングの関数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W, name=\"\"):\n",
    "    if name ==\"\":\n",
    "        return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "    else:\n",
    "        return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME', name=name)        \n",
    "\n",
    "def max_pool(x,ks,ss, name=\"\"):\n",
    "    if name == \"\":\n",
    "        return tf.nn.max_pool(x, ksize=[1, ks, ks, 1],\n",
    "                        strides=[1, ss, ss, 1], padding='SAME')\n",
    "    else:\n",
    "        return tf.nn.max_pool(x, ksize=[1, ks, ks, 1],\n",
    "                        strides=[1, ss, ss, 1], padding='SAME', name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# モデルの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# モデルの作成\n",
    "np.random.seed(19601228)\n",
    "tf.set_random_seed(19601228)\n",
    "\n",
    "# num_filters1 = 4\n",
    "# num_filters2 = 4\n",
    "# num_hidden_units = 196\n",
    "\n",
    "class NN:\n",
    "    def __init__(self, learning_rate=0.001,num_filters1 = 32,num_filters2 = 64,num_hidden_units = 1024):\n",
    "        with tf.Graph().as_default():\n",
    "            self.model(learning_rate)\n",
    "            self.session()\n",
    "    \n",
    "    def model(self, learning_rate,num_filters1 = 32,num_filters2 = 64,num_hidden_units = 1024):\n",
    "        with tf.name_scope(\"CN1\"):\n",
    "            ideal = tf.placeholder(tf.float32, [None, 10], name=\"ideal\")\n",
    "            img = tf.placeholder(tf.float32, [None, 784], name=\"input_data\")  \n",
    "            \n",
    "            x_image = tf.reshape(img, [-1,28,28,1])\n",
    "            convM1 = weight_variable([5,5,1,num_filters1], name=\"convM1\")\n",
    "            b_conv1 = bias_variable([num_filters1])\n",
    "            h_conv1 = tf.nn.relu(conv2d(x_image, convM1)+b_conv1)\n",
    "            h_pool1 = max_pool(h_conv1, ks=2,ss=2, name = \"pool1\")\n",
    "            \n",
    "        with tf.name_scope(\"CN2\"):    \n",
    "            convM2 = weight_variable([5,5,num_filters1,num_filters2], name=\"convM2\")\n",
    "            b_conv2 = bias_variable([num_filters2])\n",
    "            h_conv2 = tf.nn.relu(conv2d(h_pool1, convM2)+b_conv2)\n",
    "            h_pool2 = max_pool(h_conv2,ks=2,ss=2, name=\"pool2\")\n",
    "\n",
    "        with tf.name_scope(\"hidden\"):\n",
    "            nflathpool2 = 7*7*num_filters2\n",
    "            h_pool2Flat = tf.reshape(h_pool2,[-1,nflathpool2])\n",
    "            W_hidden = weight_variable([nflathpool2, num_hidden_units], name=\"W_hidden\")\n",
    "            b_hidden = bias_variable([num_hidden_units])            \n",
    "            h_hidden = tf.nn.relu(tf.matmul(h_pool2Flat,W_hidden)+b_hidden, name=\"h_hidden\")\n",
    "            \n",
    "            keep_prob = tf.placeholder(tf.float32) # ドロップアウト時のキープ率のプレースフォルダ\n",
    "            h_keep = tf.nn.dropout(h_hidden,keep_prob, name=\"h_keep\")  \n",
    "            \n",
    "        with tf.name_scope(\"output\"):\n",
    "            W_out = weight_variable([num_hidden_units, 10], name=\"W_out\")\n",
    "            b_out = bias_variable([10])\n",
    "            # out = tf.nn.softmax(tf.matmul(h_keep,W_out)+b_out, name=\"softmax-output\")            \n",
    "            out = tf.nn.softmax(tf.matmul(h_hidden,W_out)+b_out, name=\"softmax-output\")            \n",
    "            \n",
    "        with tf.name_scope(\"Optimizer\") as scope:\n",
    "            loss = -tf.reduce_sum(ideal*tf.log(out), name=\"loss\")\n",
    "            # train_step = tf.train.GradientDescentOptimizer(0.00002).minimize(loss)\n",
    "            train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "        \n",
    "        with tf.name_scope(\"Evaluator\") as scope:\n",
    "            correct_prediction = tf.equal(tf.argmax(out,1),tf.argmax(ideal,1), name=\"correct\")\n",
    "            accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name=\"accuracy\")\n",
    "            \n",
    "        self.ideal = ideal\n",
    "        self.img = img\n",
    "        self.keep_prob = keep_prob\n",
    "\n",
    "        self.out = out\n",
    "        self.train_step = train_step\n",
    "        self.loss = loss\n",
    "        self.accuracy = accuracy\n",
    "        self.convM1, self.convM2, self.W_hidden, self.W_out = convM1,convM2, W_hidden, W_out\n",
    "        self.h_pool1,self.h_pool2 = h_pool1, h_pool2\n",
    "\n",
    "        tf.summary.scalar(\"loss\", loss)\n",
    "        tf.summary.scalar(\"accuracy\", accuracy)\n",
    "        tf.summary.histogram(\"Matrix1\", convM1)\n",
    "        tf.summary.histogram(\"Matrix2\", convM2)\n",
    "        tf.summary.histogram(\"W_hidden\", W_hidden)\n",
    "        tf.summary.histogram(\"W_pool1\", h_pool1)\n",
    "        tf.summary.histogram(\"W_pool2t\", h_pool2)\n",
    "        tf.summary.histogram(\"out\", out)\n",
    "        \n",
    "    def session(self):\n",
    "        sess = tf.InteractiveSession()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        # sess.run(tf.local_variables_initializer())\n",
    "        summary = tf.summary.merge_all()\n",
    "        writer = tf.summary.FileWriter(\"log8\", sess.graph)\n",
    "                               \n",
    "        self.sess = sess\n",
    "        self.summary = summary\n",
    "        self.writer = writer\n",
    "        self.saver = saver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# セッションの開始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nn = NN(learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 100, Loss: 2330.462891, Accuracy: 0.930000\n",
      "Step: 200, Loss: 1874.548828, Accuracy: 0.946800\n",
      "Step: 300, Loss: 1600.456299, Accuracy: 0.952300\n",
      "Step: 400, Loss: 1500.534424, Accuracy: 0.955400\n",
      "Step: 500, Loss: 1228.771362, Accuracy: 0.964600\n",
      "Step: 600, Loss: 1050.802124, Accuracy: 0.967800\n",
      "Step: 700, Loss: 1086.759033, Accuracy: 0.965700\n",
      "Step: 800, Loss: 995.476379, Accuracy: 0.968600\n",
      "Step: 900, Loss: 1171.880615, Accuracy: 0.962700\n",
      "Step: 1000, Loss: 921.742676, Accuracy: 0.971000\n",
      "Step: 1100, Loss: 1056.264404, Accuracy: 0.964900\n",
      "Step: 1200, Loss: 1059.226562, Accuracy: 0.965600\n",
      "Step: 1300, Loss: 909.913818, Accuracy: 0.970900\n",
      "Step: 1400, Loss: 1001.597839, Accuracy: 0.967300\n",
      "Step: 1500, Loss: 737.807861, Accuracy: 0.977200\n",
      "Step: 1600, Loss: 702.854553, Accuracy: 0.978200\n",
      "Step: 1700, Loss: 695.326416, Accuracy: 0.978900\n",
      "Step: 1800, Loss: 697.790833, Accuracy: 0.977200\n",
      "Step: 1900, Loss: 632.134949, Accuracy: 0.980000\n",
      "Step: 2000, Loss: 687.796204, Accuracy: 0.977300\n"
     ]
    }
   ],
   "source": [
    "times = 0\n",
    "for _ in range(2000):\n",
    "    times += 1\n",
    "    batch_xs,batch_ts = mnist.train.next_batch(30)\n",
    "    nn.sess.run(nn.train_step, feed_dict={nn.keep_prob:0.5,nn.img:batch_xs, nn.ideal:batch_ts})\n",
    "    if times % 100 == 0:\n",
    "        summary,loss_val, acc_val = nn.sess.run([nn.summary,nn.loss,nn.accuracy],\n",
    "                feed_dict={nn.keep_prob:1.0,nn.img:mnist.test.images, nn.ideal:mnist.test.labels})\n",
    "        print(\"Step: {0:d}, Loss: {1:f}, Accuracy: {2:f}\".format(times, loss_val, acc_val))\n",
    "        nn.writer.add_summary(summary,times)\n",
    "        # nn.saver.save(nn.sess, '.\\mysession', global_step = times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 98%!\n",
    "畳み込み層を１段目２段目とも４、隠れ層196でも98％\n",
    "\n",
    "普通の隠れ層１のNNや畳み込み層１隠れ層なしのNNでも98％は到達するのだから当然なのかもしれない。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習結果を用いて文字認識してみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,15))\n",
    "def plotchr(image,label1,label2, i):\n",
    "    sns.set_context(\"talk\")\n",
    "    plt.subplot(10,6,i)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.title(\"%d / %d\" % (np.argmax(label1),np.argmax(label2)))\n",
    "    plt.imshow(image,cmap=plt.cm.gray_r)\n",
    "    \n",
    "images, labels = mnist.test.images, mnist.test.labels\n",
    "p_val = nn.sess.run(nn.out, feed_dict={nn.img:images, nn.ideal:labels})\n",
    "\n",
    "# 0～9 と判定されたものについて、それぞれ正の例を３つ、負の例を３つ表示する\n",
    "picnumber = 0\n",
    "for i in range(10):\n",
    "    c = 0\n",
    "    for (image, label, pred) in zip(images, labels, p_val):\n",
    "        prediction,actual = np.argmax(pred), np.argmax(label)\n",
    "        if prediction != i:  # \n",
    "            continue\n",
    "        if(c<3 and i == actual) or (c>=3 and i != actual):\n",
    "            picnumber += 1\n",
    "            plotchr(image.reshape((28,28)),pred,label,picnumber)\n",
    "            c += 1\n",
    "            if c > 5:\n",
    "                break\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_filters=16\n",
    "\n",
    "def showFilterEffect(num_filters, start, filters,imgs):\n",
    "    fig = plt.figure(figsize=(10,num_filters+1))\n",
    "    for i in range(num_filters):\n",
    "        subplot = fig.add_subplot(num_filters+1, 10, 10*(i+1)+1)\n",
    "        sns.heatmap(filters[:,:,0,i],yticklabels=[],xticklabels=[],\n",
    "                cmap=plt.cm.bwr,cbar=False,annot=False,square=True)\n",
    "\n",
    "    for i in range(9):\n",
    "        subplot = fig.add_subplot(num_filters+1, 10, i+2)\n",
    "        oimg = mnist.test.images[start+i].reshape((28,28))\n",
    "        title = '{:d}'.format(np.argmax(mnist.test.labels[start+i]))\n",
    "        subplot.set_title(title)\n",
    "        sns.heatmap(oimg,yticklabels=[],xticklabels=[],\n",
    "                cmap=plt.cm.binary,cbar=False,annot=False,square=True)\n",
    "\n",
    "        for f in range(num_filters):\n",
    "            subplot = fig.add_subplot(num_filters+1, 10, 10*(f+1)+i+2)\n",
    "            sns.heatmap(imgs[i][:,:,f],yticklabels=[],xticklabels=[],\n",
    "                cmap=plt.cm.binary,cbar=False,annot=False,square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filter_vals, conv_vals, pool_vals = nn.sess.run(\n",
    "    [nn.W_conv, nn.h_conv, nn.h_pool], feed_dict={nn.img:mnist.test.images[0:10]})\n",
    "showFilterEffect(16,0,filter_vals,conv_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "showFilterEffect(16,0,filter_vals,pool_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,10))\n",
    "c=0\n",
    "for i in range(len(mnist.test.images)):\n",
    "    image = mnist.test.images[i:i+1]\n",
    "    label = mnist.test.labels[i]\n",
    "    p_val = nn.sess.run(nn.out, feed_dict={nn.img:image})\n",
    "    pred = p_val[0]\n",
    "    prediction, actual = np.argmax(pred), np.argmax(label)\n",
    "    if prediction == actual:\n",
    "        continue\n",
    "    subplot = fig.add_subplot(5,4,c*2+1)\n",
    "    subplot.set_xticks([])\n",
    "    subplot.set_yticks([])\n",
    "    subplot.set_title('{} / {}'.format(prediction, actual))\n",
    "    subplot.imshow(image.reshape((28,28)), vmin=0, vmax=1,\n",
    "                   cmap=plt.cm.binary, interpolation=\"nearest\")\n",
    "    subplot = fig.add_subplot(5,4,c*2+2)\n",
    "    subplot.set_xticks(range(10))\n",
    "    subplot.set_xlim(-0.5,9.5)\n",
    "    subplot.set_ylim(0,1)\n",
    "    subplot.bar(range(10), pred, align='center')\n",
    "    c += 1\n",
    "    if c == 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
